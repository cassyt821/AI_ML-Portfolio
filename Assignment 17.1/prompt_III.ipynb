{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data represents 17 marketing campaigns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fields have \"Unknown\" values: job, marital, education, default, housing, and loan, which indicates missing values. <br>\n",
    "<br>\n",
    "The fields also appear to be in appropriate dtypes given their ranges of possible values. It may be useful to coerce the \"yes/no\" fields into a Boolean datatype and drop the \"Unknown\" values; this includes the target variable. <br>\n",
    "<br>\n",
    "The categorical fields may be better handled through one-hot encoding or ordinal encoding. <br>\n",
    "<br>\n",
    "Fields to be handled with ordinal encoding: education and poutcome. <br>\n",
    "<br>\n",
    "Fields to be handled with one-hot encoding: job, marital, default, housing, loan, and contact. <br>\n",
    "<br>\n",
    "Through independent research and exploration of online resources, including ChatGPT, I learned about alternate methods of encoding month and weekday information, which preserves the cyclicality of these fields and minimizes the models internalizing misleading correlations that could arise if using one-hot encoding or ordinal encoding. As a result, I think it would be best to implement sin/cos encoding for the month and weekday fields. <br>\n",
    "\n",
    "ChatGPT. \"Discussion on Encoding Month and Weekday for Machine Learning Models.\" OpenAI, 25 March 2025. <br>\n",
    "\n",
    "Lewinson, Eryk. \"Three Approaches to Encoding Time Information as Features for ML Models.\" NVIDIA Developer Technical Blog. 17 February 2022. Accessed 25 March 2025, https://developer.nvidia.com/blog/three-approaches-to-encoding-time-information-as-features-for-ml-models/\n",
    "<br>\n",
    "<br> Scikit-learn guidance for implementing cyclical feature engineering: <br>\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Objective: To identify the conditions under which a contact is likely to subscribe. These conditions include: <br>\n",
    "- Characteristics of the individual, like employment status, marital status, etc <br>\n",
    "- Characteristics of timing, like month, day of the week <br>\n",
    "- Characteristics related to previous campaigns, like the outcomes or number of contacts from previous campaigns directed at this customer <br>\n",
    "- Characteristics of the economy at the time of contact, like CPI. <br>\n",
    "<br>\n",
    "This business objective will be addressed by way of building a predictive model that identifies which characteristics or groups of characteristics are most correllated with a successful subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import StandardScaler, OneHotEncoding, ColumnTransformer from SciKit Learn\n",
    "#Import Numpy\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30488 entries, 0 to 30487\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             30488 non-null  int64  \n",
      " 1   job             30488 non-null  object \n",
      " 2   marital         30488 non-null  object \n",
      " 3   education       30488 non-null  object \n",
      " 4   default         30488 non-null  object \n",
      " 5   housing         30488 non-null  object \n",
      " 6   loan            30488 non-null  object \n",
      " 7   contact         30488 non-null  object \n",
      " 8   month           30488 non-null  float64\n",
      " 9   day_of_week     30488 non-null  float64\n",
      " 10  campaign        30488 non-null  int64  \n",
      " 11  pdays           30488 non-null  int64  \n",
      " 12  previous        30488 non-null  int64  \n",
      " 13  poutcome        30488 non-null  object \n",
      " 14  emp.var.rate    30488 non-null  float64\n",
      " 15  cons.price.idx  30488 non-null  float64\n",
      " 16  cons.conf.idx   30488 non-null  float64\n",
      " 17  euribor3m       30488 non-null  float64\n",
      " 18  nr.employed     30488 non-null  float64\n",
      " 19  y               30488 non-null  object \n",
      "dtypes: float64(7), int64(4), object(9)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Drop the \"duration\" column, based on the guidance of the field description above.\n",
    "#Drop rows where any of the values are \"Unknown\"\n",
    "df_working = df.drop(columns=['duration']).where(df != 'unknown')\n",
    "df_working.dropna(inplace=True, ignore_index=True)\n",
    "\n",
    "#Declare column types and corresponding fields\n",
    "columns_ordinal = ['education', 'poutcome']\n",
    "columns_categorical = ['job', 'marital']\n",
    "columns_binary = ['default', 'housing', 'loan', 'contact']\n",
    "columns_cyclic = ['month', 'day_of_week']\n",
    "#Define ordinal column value ranges\n",
    "ordinal_education = ['basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree']\n",
    "ordinal_poutcome = ['failure','nonexistent','success']\n",
    "\n",
    "#Translate month and day of week to numerical values\n",
    "month_mapper = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "wkday_mapper = {'mon': 1, 'tue': 2, 'wed': 3, 'thu': 4, 'fri': 5}\n",
    "\n",
    "df_working['month'] = df_working['month'].replace(month_mapper).astype(float)\n",
    "df_working['day_of_week'] = df_working['day_of_week'].replace(wkday_mapper).astype(float)\n",
    "\n",
    "df_working.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for cyclical encoding.\n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x/(2*period*np.pi)))\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x/(2*period*np.pi)))\n",
    "#Define Column Transformer\n",
    "full_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[ordinal_education, ordinal_poutcome]), columns_ordinal),\n",
    "        (\"categorical\", OneHotEncoder(), columns_categorical),\n",
    "        (\"binary\", OneHotEncoder(drop='if_binary'), columns_binary),\n",
    "        (\"month_sin\", sin_transformer(12), ['month']),\n",
    "        (\"month_cos\", cos_transformer(12), ['month']),\n",
    "        (\"weekday_sin\", sin_transformer(7), ['day_of_week']),\n",
    "        (\"weekday_cos\", cos_transformer(7), ['day_of_week'])\n",
    "    ],\n",
    "    remainder=StandardScaler() #Perform standard scaling for the remaining numerical values\n",
    ")\n",
    "df_transformed = full_transformer.fit_transform(df_working.drop(columns=['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, y_train, y_test = train_test_split(df_working.drop(columns=['y']),\n",
    "                                                                                         df_working['y'],\n",
    "                                                                         train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11\n",
      "0.89\n"
     ]
    }
   ],
   "source": [
    "#The model should be more accurate than assuming all contacts will subscribe. \n",
    "baseline_performance_y = len(df['y'].loc[df['y'] == 'yes'])/len(df['y'])\n",
    "baseline_performance_x = 1 - baseline_performance_y\n",
    "print(np.round(baseline_performance_y,2))\n",
    "print(np.round(baseline_performance_x,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be 89% accurate simply by guessing that everyone will not convert. Therefore, our classifier should be at least 89-90% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873458288821987\n"
     ]
    }
   ],
   "source": [
    "print(baseline_performance_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8922597572974745"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('transform', full_transformer),\n",
    "    ('logistic regression', LogisticRegression())\n",
    "     ])\n",
    "logistic_model = logistic_pipeline.fit(features_train, y_train)\n",
    "logistic_model.score(features_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy of the Logistic Regression model is 89%, just barely improving upon the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['Logistic Regression', 'KNN', 'Decision Tree', 'SVM']\n",
    "train_time = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "starttime = datetime.now()\n",
    "#Record Logistic Regression Metrics\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('transform', full_transformer),\n",
    "    ('logistic regression', LogisticRegression())\n",
    "     ])\n",
    "logistic_pipeline.fit(features_train, y_train)\n",
    "endtime = datetime.now()\n",
    "train_time.append(endtime - starttime)\n",
    "train_accuracy.append(logistic_pipeline.score(features_train, y_train))\n",
    "test_accuracy.append(logistic_pipeline.score(features_test, y_test))\n",
    "endtime = datetime.now()\n",
    "\n",
    "starttime = datetime.now()\n",
    "#Record KNN Metrics\n",
    "knn_pipeline = Pipeline([\n",
    "    ('transform', full_transformer),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "     ])\n",
    "knn_pipeline.fit(features_train, y_train)\n",
    "endtime = datetime.now()\n",
    "train_time.append(endtime - starttime)\n",
    "train_accuracy.append(knn_pipeline.score(features_train, y_train))\n",
    "test_accuracy.append(knn_pipeline.score(features_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record Decision Tree Metrics\n",
    "starttime = datetime.now()\n",
    "dtree_pipeline = Pipeline([\n",
    "    ('transform', full_transformer),\n",
    "    ('Decision_Tree', DecisionTreeClassifier())\n",
    "     ])\n",
    "dtree_pipeline.fit(features_train, y_train)\n",
    "endtime = datetime.now()\n",
    "train_time.append(endtime - starttime)\n",
    "train_accuracy.append(dtree_pipeline.score(features_train, y_train))\n",
    "test_accuracy.append(dtree_pipeline.score(features_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record SVM Metrics\n",
    "starttime = datetime.now()\n",
    "svm_pipeline = Pipeline([\n",
    "    ('transform', full_transformer),\n",
    "    ('svm', SVC())\n",
    "     ])\n",
    "svm_pipeline.fit(features_train, y_train)\n",
    "endtime = datetime.now()\n",
    "train_time.append(endtime - starttime)\n",
    "train_accuracy.append(svm_pipeline.score(features_train, y_train))\n",
    "test_accuracy.append(svm_pipeline.score(features_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = pd.DataFrame(data={'Model': model, 'Train Time': train_time, 'Train Accuracy': train_accuracy, \n",
    "                                   'Test Accuracy': test_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>123</td>\n",
       "      <td>0.888028</td>\n",
       "      <td>0.892260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>33</td>\n",
       "      <td>0.903362</td>\n",
       "      <td>0.884552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>140</td>\n",
       "      <td>0.994301</td>\n",
       "      <td>0.819121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>210</td>\n",
       "      <td>0.887372</td>\n",
       "      <td>0.889144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
       "0  Logistic Regression         123        0.888028       0.892260\n",
       "1                  KNN          33        0.903362       0.884552\n",
       "2        Decision Tree         140        0.994301       0.819121\n",
       "3                  SVM         210        0.887372       0.889144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison Findings\n",
    "df_comparison['Train Time'] = df_comparison['Train Time'].dt.components['milliseconds']\n",
    "display(df_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN Classifier was the fastest model to train, at 33 milliseconds. It has an acceptable train accuracy, but the test accuracy is actually lower than the baseline performance standard. The Decision Tree classifier was the second longest model to train (140 milliseconds). It also has a 99% accuracy on the training data and 82% accuracy on the test data. These metrics indicate that the KNN and Decision Tree classifiers are overfit, with the Decision Tree classifier being the most overfit model of the 4. <br>\n",
    "\n",
    "The Support Vector Classifier model took the longest to train, at 210 milliseconds. The training accuracy is pretty close to the baseline performance standard, and the test accuracy shows slight improvement. This is a promising sign that this model is not terribly overfit. <br>\n",
    "\n",
    "Of the 4 models, the Logistic Regression model is the best model to run on default settings. It is the second fastest model to train, and the test accuracy is better than the train accuracy, both of which are better than the baseline performance metric. Even though both accuracy scores are better than the baseline performance metric, there is no obvious sign that the model is overfit, based on the accuracy scored on the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based purely on ethical concerns, I think we should not include the gender feature. It risks ingraining systematic prejudices in a model, and if that model were applied in a real business setting, this risks propagating or further solidifying systematic gender-based inequality in that business's practices. Furthermore, social conception of gender is still a dynamic dimension of sociopolitics, and it is imprudent to integrate, as a variable, a label that is an unresolved social and equity minefield. <br>\n",
    "<br>\n",
    "I'm going to focus on hyperparameter exploration for the different models, but some additional features that would be interesting to explore include:<br>\n",
    "- Polynomial terms of the numeric features <br>\n",
    "- Combinations of Month and Weekday <br>\n",
    "\n",
    "Running PCA would also be interesting to explore, since there are so many dimensions in the data that I'd want to prune features that are correlated with each other. I'd also want to reduce the likelihood of overfitting resulting from noise arising from the combination of so many different dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_explore]",
   "language": "python",
   "name": "conda-env-data_explore-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
