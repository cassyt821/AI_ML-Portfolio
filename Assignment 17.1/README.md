In this project I evaluated the performance of different classification models in predicting whether a contact will subscribe to a deposit based on collected characteristics of the contact, previous interactions with the contact, and some overall metrics on the state of the economy.

The Jupyter Notebook can be found here:  Assignment 17.1/prompt_III.ipynb

Findings: 
The ideal model depends on a company's tolerance for risk, with risk-tolerant indicating that the company favors more subscriptions at the risk of following more false leads, and risk-averse indicating that the company favors avoiding unnecessary expenditure of resources over identifying successful subscriptions.
I compared 4 different families of modelling on their default characteristics: Logistic Regression, K Nearest Neighbors, Decision Tree, and Support Vector Machine classifiers. Preliminary findings favor Logistic Regression as the model to use because of its balance between time to train, test set accuracy, and a reasonable training set accuracy that has no obvious signs of overfitting. Even though the test set accuracy was only a marginal improvement on assuming that no one would subscribe to a deposit, it's still an improvement over the alternative.

However, further investigation suggests that the Decision Tree classifier is more desirable from a business perspective because it minimizes false negatives and maximizes true positives (of the 4 models). In doing so, it strikes a healthier balance for the risk-tolerant business by correctly discouraging the business from allocating resources to the contacts that do not convert while minimizing the amount of subsriptions that would be passed by (false negatives). Depending on the business's appetite for risk or flexibility, the KNN classifier model is more conservative approach to prediction that would still reasonably minimize false negatives and maximize true positives.

SVM minimizes false positives, but the tradeoff is that it has more false negatives, which means more potentially foregone business. This is the ideal model for a risk-averse business. The Logistic Regression classifier is still conservative but more accurate, thus making it a more balanced model for a risk-averse business.

It would be interesting to pare down the number of features that go into the model or training models on one set of features. The current dataset includes characteristics specific to the individual contact, campaign-focused characteristics specific to the individual contact, general information on the economy, and general information on the time of contact. Hyperparameter tuning is an option that focuses on tuning the complexity of the model, but another option is deliberately feeding features that focus on a dimension of causality (eg. person, campaign, time of year/week, or economy health) or specific combinations of the dimensions.
